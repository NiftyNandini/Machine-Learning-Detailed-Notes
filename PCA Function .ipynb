{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac792f57",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA) in Machine Learning\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used in machine learning to simplify complex datasets. It is primarily used to reduce the number of features while retaining the most important information in the data. PCA achieves this by transforming the data into a new set of variables called **Principal Components**, which are uncorrelated and capture the maximum variance in the dataset.\n",
    "\n",
    "Principal Component Analysis (PCA) is used to reduce the dimensionality of a data set by finding a new set of variables, smaller than the original set of variables, retaining most of the sampleâ€™s information, and useful for the regression and classification of data.\n",
    "\n",
    "\n",
    "## Key Points:\n",
    "- **Purpose**: Reduce dimensionality and remove noise while retaining important patterns.\n",
    "- **Usage**: Helps in visualization, speed up machine learning algorithms, and prevent overfitting.\n",
    "\n",
    "## How PCA Works:\n",
    "1. **Standardization**: The data is standardized to have a mean of 0 and a standard deviation of 1, making it unit-free.\n",
    "2. **Covariance Matrix Computation**: A covariance matrix is created to identify correlations between features.\n",
    "3. **Eigen Decomposition**: Eigenvalues and eigenvectors are calculated from the covariance matrix to identify the principal components.\n",
    "   - **Eigenvalues** determine the amount of variance each principal component explains.\n",
    "   - **Eigenvectors** point in the direction of the principal components.\n",
    "4. **Feature Vector Formation**: Select the top `k` eigenvectors that correspond to the largest eigenvalues.\n",
    "5. **Data Projection**: The original data is projected onto the new feature space formed by the selected principal components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f389db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.96296464 0.03703536]\n",
      "Principal Components:\n",
      " [[-1.08643242 -0.22352364]\n",
      " [ 2.3089372   0.17808082]\n",
      " [-1.24191895  0.501509  ]\n",
      " [-0.34078247  0.16991864]\n",
      " [-2.18429003 -0.26475825]\n",
      " [-1.16073946  0.23048082]\n",
      " [ 0.09260467 -0.45331721]\n",
      " [ 1.48210777  0.05566672]\n",
      " [ 0.56722643  0.02130455]\n",
      " [ 1.56328726 -0.21536146]]\n"
     ]
    }
   ],
   "source": [
    "## PCA Function in Python (using `scikit-learn`):\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset\n",
    "X = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2, 1.6], [1, 1.1], [1.5, 1.6], [1.1, 0.9]])\n",
    "\n",
    "# Standardizing the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Applying PCA\n",
    "pca = PCA(n_components=2)  # Number of components to keep\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Principal Components:\\n\", X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ebee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
